import gradio as gr
import soundfile as sf
import tempfile
import torch

print("‚è≥ ƒêang kh·ªüi ƒë·ªông VieNeu-TTS...")
# Import vieneutts
from vieneutts import VieNeuTTS

# Kh·ªüi t·∫°o model
print("üì¶ ƒêang t·∫£i model...")
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"üñ•Ô∏è S·ª≠ d·ª•ng thi·∫øt b·ªã: {device.upper()}")

tts = VieNeuTTS(
    backbone_repo="pnnbao-ump/VieNeu-TTS",
    backbone_device=device,
    codec_repo="neuphonic/neucodec",
    codec_device=device
)
print("‚úÖ Model ƒë√£ t·∫£i xong!")

# Danh s√°ch gi·ªçng m·∫´u (b·ªè id_0006)
VOICE_SAMPLES = {
    "Nam 1 (id_0001)": {
        "audio": "./sample/id_0001.wav",
        "text": "./sample/id_0001.txt"
    },
    "N·ªØ 1 (id_0002)": {
        "audio": "./sample/id_0002.wav",
        "text": "./sample/id_0002.txt"
    },
    "Nam 2 (id_0003)": {
        "audio": "./sample/id_0003.wav",
        "text": "./sample/id_0003.txt"
    },
    "N·ªØ 2 (id_0004)": {
        "audio": "./sample/id_0004.wav",
        "text": "./sample/id_0004.txt"
    },
    "Nam 3 (id_0005)": {
        "audio": "./sample/id_0005.wav",
        "text": "./sample/id_0005.txt"
    },
    "Nam 4 (id_0007)": {
        "audio": "./sample/id_0007.wav",
        "text": "./sample/id_0007.txt"
    }
}

def synthesize_speech(text, voice_choice, custom_audio=None, custom_text=None):
    """
    T·ªïng h·ª£p gi·ªçng n√≥i t·ª´ vƒÉn b·∫£n
    """
    try:
        # Ki·ªÉm tra text input
        if not text or text.strip() == "":
            return None, "‚ùå Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c·∫ßn t·ªïng h·ª£p"
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i text
        if len(text) > 250:
            return None, "‚ùå VƒÉn b·∫£n qu√° d√†i! Vui l√≤ng nh·∫≠p t·ªëi ƒëa 250 k√Ω t·ª±"
        
        # X√°c ƒë·ªãnh reference audio v√† text
        if custom_audio is not None and custom_text:
            ref_audio_path = custom_audio
            ref_text = custom_text
            print("üé® S·ª≠ d·ª•ng gi·ªçng t√πy ch·ªânh")
        elif voice_choice in VOICE_SAMPLES:
            ref_audio_path = VOICE_SAMPLES[voice_choice]["audio"]
            ref_text_path = VOICE_SAMPLES[voice_choice]["text"]
            with open(ref_text_path, "r", encoding="utf-8") as f:
                ref_text = f.read()
            print(f"üé§ S·ª≠ d·ª•ng gi·ªçng: {voice_choice}")
        else:
            return None, "‚ùå Vui l√≤ng ch·ªçn gi·ªçng ho·∫∑c t·∫£i l√™n audio t√πy ch·ªânh"
        
        # Encode reference audio
        print(f"üìù ƒêang x·ª≠ l√Ω: {text[:50]}...")
        ref_codes = tts.encode_reference(ref_audio_path)
        
        # T·ªïng h·ª£p gi·ªçng n√≥i
        print(f"üéµ ƒêang t·ªïng h·ª£p gi·ªçng n√≥i tr√™n {device.upper()}...")
        wav = tts.infer(text, ref_codes, ref_text)
        
        # L∆∞u file t·∫°m
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            sf.write(tmp_file.name, wav, 24000)
            output_path = tmp_file.name
        
        print("‚úÖ Ho√†n th√†nh!")
        return output_path, f"‚úÖ T·ªïng h·ª£p th√†nh c√¥ng tr√™n {device.upper()}!"
        
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")
        import traceback
        traceback.print_exc()
        return None, f"‚ùå L·ªói: {str(e)}"

# C√°c v√≠ d·ª• m·∫´u
examples = [
    ["Legacy l√† m·ªôt b·ªô phim ƒë·ªôt ph√° v·ªÅ m·∫∑t √¢m nh·∫°c, quay phim, hi·ªáu ·ª©ng ƒë·∫∑c bi·ªát, v√† t√¥i r·∫•t m·ª´ng v√¨ cu·ªëi c√πng n√≥ c≈©ng ƒë∆∞·ª£c c·∫£ gi·ªõi ph√™ b√¨nh l·∫´n ng∆∞·ªùi h√¢m m·ªô ƒë√°nh gi√° l·∫°i. Ch√∫ng ta ƒë√£ qu√° b·∫•t c√¥ng v·ªõi b·ªô phim n√†y v√†o nƒÉm 2010.", "Nam 1 (id_0001)"],
    ["T·ª´ nhi·ªÅu ngu·ªìn t√†i li·ªáu l·ªãch s·ª≠, c√≥ th·ªÉ th·∫•y nu√¥i con theo phong c√°ch Do Th√°i kh√¥ng ch·ªâ t·ªët cho ƒë·ª©a tr·∫ª m√† c√≤n t·ªët cho c·∫£ c√°c b·∫≠c cha m·∫π.", "N·ªØ 1 (id_0002)"],
    ["C√°c b√°c sƒ© ƒëang nghi√™n c·ª©u m·ªôt lo·∫°i vaccine m·ªõi ch·ªëng l·∫°i virus c√∫m m√πa. Th√≠ nghi·ªám l√¢m s√†ng cho th·∫•y ph·∫£n ·ª©ng mi·ªÖn d·ªãch m·∫°nh m·∫Ω v√† √≠t t√°c d·ª•ng ph·ª•, m·ªü ra hy v·ªçng ph√≤ng ch·ªëng d·ªãch b·ªánh hi·ªáu qu·∫£ h∆°n trong t∆∞∆°ng lai.", "Nam 2 (id_0003)"],
]

# Custom CSS
custom_css = """
.gradio-container {
    max-width: 1000px !important;
    margin: 0 auto !important;
    padding: 20px !important;
}
.contain {
    max-width: 1000px !important;
    margin: 0 auto !important;
}
#warning {
    background-color: #fff3cd;
    border: 1px solid #ffc107;
    border-radius: 5px;
    padding: 10px;
    margin: 10px 0;
}
#info {
    background-color: #d1ecf1;
    border: 1px solid #17a2b8;
    border-radius: 5px;
    padding: 10px;
    margin: 10px 0;
}
"""

# T·∫°o giao di·ªán Gradio
with gr.Blocks(title="VieNeu-TTS Local", css=custom_css, theme=gr.themes.Soft()) as demo:
    gr.Markdown("""
    # üéôÔ∏è VieNeu-TTS: Vietnamese Text-to-Speech (Local Version)

    H·ªá th·ªëng t·ªïng h·ª£p ti·∫øng n√≥i ti·∫øng Vi·ªát ƒë∆∞·ª£c **finetune t·ª´ NeuTTS-Air** - m·ªôt m√¥ h√¨nh TTS ti√™n ti·∫øn s·ª≠ d·ª•ng Large Language Model v√† Neural Codec.

    T√°c gi·∫£: [Ph·∫°m Nguy·ªÖn Ng·ªçc B·∫£o](https://github.com/pnnbao97)  
    Model: [VieNeu-TTS](https://huggingface.co/pnnbao-ump/VieNeu-TTS)  
    Code: [GitHub](https://github.com/pnnbao97/VieNeu-TTS)
    """)
    
    with gr.Row():
        with gr.Column():
            # Input text
            text_input = gr.Textbox(
                label="üìù VƒÉn b·∫£n ƒë·∫ßu v√†o (t·ªëi ƒëa 250 k√Ω t·ª±)",
                placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát...",
                lines=4,
                max_lines=6,
                value="Legacy l√† m·ªôt b·ªô phim ƒë·ªôt ph√° v·ªÅ m·∫∑t √¢m nh·∫°c, quay phim, hi·ªáu ·ª©ng ƒë·∫∑c bi·ªát, v√† t√¥i r·∫•t m·ª´ng v√¨ cu·ªëi c√πng n√≥ c≈©ng ƒë∆∞·ª£c c·∫£ gi·ªõi ph√™ b√¨nh l·∫´n ng∆∞·ªùi h√¢m m·ªô ƒë√°nh gi√° l·∫°i. Ch√∫ng ta ƒë√£ qu√° b·∫•t c√¥ng v·ªõi b·ªô phim n√†y v√†o nƒÉm 2010."
            )
            
            # Character counter
            char_count = gr.Markdown("209 / 250 k√Ω t·ª±")
            
            # Voice selection
            voice_select = gr.Radio(
                choices=list(VOICE_SAMPLES.keys()),
                label="üé§ Ch·ªçn gi·ªçng m·∫´u",
                value="Nam 1 (id_0001)",
                info="Gi·ªçng l·∫ª: Nam | Gi·ªçng ch·∫µn: N·ªØ"
            )
            
            # Custom voice option
            with gr.Accordion("üé® Ho·∫∑c s·ª≠ d·ª•ng gi·ªçng t√πy ch·ªânh", open=False):
                gr.Markdown("""
                **H∆∞·ªõng d·∫´n:**
                - Upload file audio (.wav) v√† nh·∫≠p n·ªôi dung text ch√≠nh x√°c t∆∞∆°ng ·ª©ng
                - **L∆∞u √Ω:** Ch·∫•t l∆∞·ª£ng c√≥ th·ªÉ kh√¥ng t·ªët b·∫±ng c√°c gi·ªçng m·∫´u trong th∆∞ m·ª•c sample
                - ƒê·ªÉ c√≥ k·∫øt qu·∫£ t·ªët nh·∫•t, h√£y finetune model tr√™n gi·ªçng c·ªßa b·∫°n t·∫°i: [finetune.ipynb](https://github.com/pnnbao-ump/VieNeuTTS/blob/main/finetune.ipynb)
                """)
                custom_audio = gr.Audio(
                    label="File audio m·∫´u",
                    type="filepath"
                )
                custom_text = gr.Textbox(
                    label="N·ªôi dung c·ªßa audio m·∫´u",
                    placeholder="Nh·∫≠p ch√≠nh x√°c n·ªôi dung...",
                    lines=2
                )
            
            # Submit button
            submit_btn = gr.Button("üéµ T·ªïng h·ª£p gi·ªçng n√≥i", variant="primary", size="lg")
        
        with gr.Column():
            # Output
            audio_output = gr.Audio(label="üîä K·∫øt qu·∫£")
            status_output = gr.Textbox(label="üìä Tr·∫°ng th√°i", interactive=False)
    
    # Examples
    gr.Markdown("### üí° V√≠ d·ª• nhanh")
    gr.Examples(
        examples=examples,
        inputs=[text_input, voice_select],
        outputs=[audio_output, status_output],
        fn=synthesize_speech,
        cache_examples=False
    )
    
    # Update character count
    def update_char_count(text):
        count = len(text) if text else 0
        color = "red" if count > 250 else "green"
        return f"<span style='color: {color}'>{count} / 250 k√Ω t·ª±</span>"
    
    text_input.change(
        fn=update_char_count,
        inputs=[text_input],
        outputs=[char_count]
    )
    
    # Event handler
    submit_btn.click(
        fn=synthesize_speech,
        inputs=[text_input, voice_select, custom_audio, custom_text],
        outputs=[audio_output, status_output]
    )
    
    gr.Markdown("""
    ---
    ### üìå Th√¥ng tin v·ªÅ gi·ªçng m·∫´u
    
    **Gi·ªçng c√≥ s·∫µn trong th∆∞ m·ª•c sample:**
    - `id_0001.wav/txt` - Nam 1 ‚úÖ
    - `id_0002.wav/txt` - N·ªØ 1 ‚úÖ
    - `id_0003.wav/txt` - Nam 2 ‚úÖ
    - `id_0004.wav/txt` - N·ªØ 2 ‚úÖ
    - `id_0005.wav/txt` - Nam 3 ‚úÖ
    - `id_0007.wav/txt` - Nam 4 ‚úÖ
    
    *C√°c file s·ªë l·∫ª: Nam gi·ªõi | C√°c file s·ªë ch·∫µn: N·ªØ gi·ªõi*
    
    **Li√™n k·∫øt:**
    - [GitHub Repository](https://github.com/pnnbao97/VieNeu-TTS)
    - [Model Card](https://huggingface.co/pnnbao-ump/VieNeu-TTS)
    - [H∆∞·ªõng d·∫´n Finetune](https://github.com/pnnbao-ump/VieNeuTTS/blob/main/finetune.ipynb)
    
    <sub>Powered by VieNeu-TTS | Built with ‚ù§Ô∏è for Vietnamese TTS</sub>
    """)

# Launch
if __name__ == "__main__":
    demo.queue(max_size=20)
    demo.launch(
        share=False,
        server_name="127.0.0.1",
        server_port=7860,
        show_error=True
    )